# LLM Provider Configuration
# Choose one or more providers and set the corresponding API keys

# ===== OpenAI =====
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# ===== Anthropic Claude =====
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ===== Google Gemini =====
GEMINI_API_KEY=...
GEMINI_MODEL=gemini-2.0-flash-exp

# ===== Ollama (local) =====
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ===== Custom Provider (OpenAI-compatible) =====
CUSTOM_API_KEY=
CUSTOM_BASE_URL=https://api.deepseek.com
CUSTOM_MODEL=deepseek-chat

# ===== Default Provider =====
# Options: openai | anthropic | gemini | ollama | custom
LLM_PROVIDER=gemini

# ===== Embedding Configuration =====
# Options: openai | gemini | local
EMBEDDING_PROVIDER=local

# For OpenAI
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small

# For Gemini
# EMBEDDING_PROVIDER=gemini
# EMBEDDING_MODEL=text-embedding-004

# For Local (Transformers.js)
# EMBEDDING_PROVIDER=local
# LOCAL_EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2
# Other options: Xenova/paraphrase-multilingual-MiniLM-L12-v2, Xenova/bge-small-en-v1.5
