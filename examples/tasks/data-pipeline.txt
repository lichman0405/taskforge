构建一个实时数据处理管道

需求：
从多个数据源（API、数据库、日志文件）采集数据，进行清洗、转换、聚合，最终存储到数据仓库并生成实时报表。

数据源：
- MySQL 业务数据库（用户、订单）
- Kafka 消息队列（实时日志）
- REST API（第三方数据）
- CSV 文件（批量导入）

处理要求：
- 数据清洗（去重、格式化、验证）
- 数据转换（JSON -> Parquet）
- 数据聚合（实时统计）
- 数据质量监控

技术栈：
- Airflow（调度）
- Apache Spark（处理）
- Kafka（流式传输）
- PostgreSQL（存储）
- Grafana（可视化）

性能指标：
- 吞吐量: 10,000 条/秒
- 延迟: < 5 秒
- 高可用性: 99.9%
